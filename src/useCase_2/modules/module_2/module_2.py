#####################################
# Second Container 
# module_2.py
#  TCP Socket Client to train a custom classifier on MNIST and evaluate GAN inference
#####################################
# Libraries
import time
from otter_net_utils import OtterUtils
tcp_tools = OtterUtils()
print("OTTER Utils class imported successfully!")
# Specific Librairies
import threading
import tensorflow as tf
import keras
import numpy as np
import logging
from PIL import Image
#####################################
device = print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

#####################################
# Placeholder for future AI class
class TensorFlowModel:
    """
    A class for handling the TensorFlow model, including data loading, training, inference, and evaluation.
    """
    def __init__(self) -> None:
        super(TensorFlowModel, self).__init__()

    def init(self, model, jsondict):
        """
        Initializes the model and prepares the dataset based on the provided JSON dictionary.
        If the dataset is 'mnist', it loads the MNIST dataset and sets up training parameters.
        Args:
            model (tf.keras.Model): The TensorFlow model to be trained.
            jsondict (dict): A dictionary containing configurations for the execution.

        Returns:
            dict: The updated JSON dictionary with additional dataset and model parameters.
        """
        if jsondict["dataset"].lower() == "mnist":
            # Load the MNIST dataset
            (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
            train_images = train_images[..., np.newaxis] / 255.0  # Normalize and add channel dimension
            test_images = test_images[..., np.newaxis] / 255.0
            jsondict["batch_size"] = 32
            jsondict["train_images"] = train_images
            jsondict["train_labels"] = train_labels
            jsondict["test_images"] = test_images
            jsondict["test_labels"] = test_labels

            # Compile the model
            model.compile(optimizer=jsondict["optimizer"],
                          loss=jsondict["criterion"],
                          metrics=['accuracy'])
            return jsondict
        else:
            return jsondict

    def training(self, model, jsondict):
        """
        Trains the TensorFlow model for one epoch using the provided training data.
        Args:
            model (tf.keras.Model): The TensorFlow model to be trained.
            jsondict (dict): A dictionary containing the training data, labels, and other configurations.
        Returns:
            tf.keras.Model: The trained model after one epoch.
        """
        model.fit(jsondict["train_images"], jsondict["train_labels"], epochs=1, batch_size=jsondict["batch_size"])
        return model

    def inference(self, model, input, jsondict):
        """
        Runs inference on a single input (image) using the TensorFlow model.
        Args:
            model (tf.keras.Model): The trained TensorFlow model.
            input (numpy.ndarray): The input image to be classified.
            jsondict (dict): A dictionary containing relevant configurations.
        Returns:
            numpy.ndarray: The model's prediction for the input image.
        """
        input_t = tf.convert_to_tensor(input)
        input_t = input_t[None, :, :, None] / 255.0  # Ensure correct shape and normalization
        return model(input_t)
    
    def inference_from_gan(self, model, gan_image):
        """
        Returns the classification score for an image generated by a Generative Adversarial Network (GAN).
        Args:
            model (tf.keras.Model): The trained TensorFlow model.
            gan_image (numpy.ndarray): The image generated by the GAN (28x28 grayscale).
        Returns:
            tuple: The predicted class index and the confidence score for the generated image.
        """
        gan_image = tf.convert_to_tensor(gan_image)
        gan_image = gan_image[None, :, :, None] / 255  # Reshape to (1, 28, 28, 1)
        predictions = model(gan_image)
        class_idx = tf.argmax(predictions, axis=1).numpy()[0]
        confidence = tf.reduce_max(predictions).numpy()
        return class_idx, confidence

    def evaluating(self, model, jsondict):
        """
        Evaluates the TensorFlow model's performance on the test set.
        Args:
            model (tf.keras.Model): The trained TensorFlow model.
            jsondict (dict): A dictionary containing the test images and labels.

        Returns:
            float: The accuracy of the model on the test set.
        """
        test_loss, test_acc = model.evaluate(jsondict["test_images"], jsondict["test_labels"], verbose=2)
        logging.info(f'Test accuracy {test_acc}')
        return test_acc
    
    def train_model(self, model, iomtdict, NUM_EPOCH):
        """
        Trains the model for a specified number of epochs.

        Args:
            model (tf.keras.Model): The TensorFlow model to be trained.
            iomtdict (dict): A dictionary containing the training data and configurations.
            NUM_EPOCH (int): The number of epochs to train the model for.
        """
        for epoch in range(NUM_EPOCH):  
            self.training(model, iomtdict)  # Train for one epoch
            logging.info(f'End of epoch {epoch}')
    
    def create_cnn_model(self,input_shape=(28, 28, 1), num_classes=10):
        """
        Defines a Convolutional Neural Network (CNN) model for MNIST classification.
        Args:
            input_shape (tuple): The shape of the input images (default is (28, 28, 1) for MNIST).
            num_classes (int): The number of output classes (default is 10 for MNIST).
        Returns:
            tf.keras.Model: The compiled CNN model ready for training.
        """
        model = tf.keras.Sequential([
            
            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
            tf.keras.layers.MaxPooling2D(2, 2),
            
            tf.keras.layers.Flatten(),
        
            tf.keras.layers.Dense(128, activation='relu'),
            
            # Output Layer with softmax activation for classification
            tf.keras.layers.Dense(num_classes, activation='softmax')
        ])
        
        # Compile the model with optimizer, loss, and metrics
        model.compile(optimizer='adam', 
                    loss='sparse_categorical_crossentropy', 
                    metrics=['accuracy'])
        
        return model

#####################################

if __name__ == "__main__":

    time.sleep(5)  # Wait during initialization of server containers
    # Log Initialization
    log_file_path = "/app/logs/container.log"
    tcp_tools.build_log_file(log_file_path) 

    ##################################### NETWORK PART #####################################
    # Network Parameters
    # C1 (Module 1 Container)
    HOST = 'module_1_container'  
    PORT = 5000             

    ########### Interaction with C1 ###########
    s = tcp_tools.init_client_TCP_connection(HOST, PORT)

    # Start the training in a separate thread
    ##########################################
    # Placeholder for future AI prediction 
    # Training here

    tools = TensorFlowModel()

    ### Keras Initialization
    NUM_CLASS = 10  # MNIST has 10 digit classes (0-9)
    NUM_EPOCH = 1
    
    # CNN model adapted for MNIST
    model = tools.create_cnn_model((28, 28, 1),10)

    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)
    optimizer = tf.keras.optimizers.Adam()

    iomtdict = {"dataset": "mnist", "criterion": criterion, "optimizer": optimizer}
    iomtdict = tools.init(model, iomtdict)


    training_thread = threading.Thread(target=tools.train_model, args=(model, iomtdict, NUM_EPOCH), daemon=True)
    training_thread.start()

    ##########################################

    # Receive the prediction from module_1
    buffer_size=650000
    data_decode = tcp_tools.wait_for_container_variable_TCP(s, buffer_size)

    # Adaptation of the module_1's inference to module_2 standard
    data_decode = np.squeeze(data_decode) 
    data_decode = (data_decode - np.min(data_decode)) / (np.max(data_decode) - np.min(data_decode))
    data_decode = np.clip(data_decode, 0, 1)
    data_decode = (data_decode * 255).astype(np.uint8)
    
    image = Image.fromarray(data_decode)
    image.save('./Gan_inference.png')
    
    data_decode = np.expand_dims(data_decode, axis=2) # (28, 28,1)

    # Ensure the training thread has finished 
    training_thread.join()
    
    class_idx, confidence = tools.inference_from_gan(model, data_decode)
    logging.info(f'GAN quality : {confidence}') 

